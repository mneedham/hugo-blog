+++
draft = true
date="2023-12-12 00:44:37"
title="Experimenting with insanely-fast-whisper"
tag=['whisper', 'til']
category=['TIL']
description="In this post, we'll learn how to use dask to parallelise the download of Parquet files from Hugging Face."
image="uploads/2023/12/dask-banner.png"
+++

:icons: font

https://player.fm/series/the-prof-g-pod-with-scott-galloway/prof-g-markets-scotts-nine-businesses

https://player.fm/series/the-prof-g-pod-with-scott-galloway/prof-g-markets-scotts-nine-businesses.json

[source, bash]
----
curl \
  -H "Accept: application/json" \
  --compressed \
  https://player.fm/series/the-prof-g-pod-with-scott-galloway/prof-g-markets-scotts-nine-businesses.json 2>/dev/null |
jq '.url'
----

[source, text]
----
"https://www.podtrac.com/pts/redirect.mp3/pdst.fm/e/chrt.fm/track/524GE/traffic.megaphone.fm/VMP5922871816.mp3?updated=1701050904"
----

[source, bash]
----
insanely-fast-whisper \
  --file-name ~/projects/learndatawithmark/whisperplus-playground/data/VMP5922871816.mp3 \
  --device-id mps \
  --model-name distil-whisper/distil-small.en \
  --batch-size 4
----

https://huggingface.co/distil-whisper/distil-small.en

[source, python]
----
import torch
from transformers import pipeline
import time

pipe = pipeline(
    "automatic-speech-recognition",
    model="distil-whisper/distil-small.en",
    torch_dtype=torch.float16,
    device="mps",
    model_kwargs={"use_flash_attention_2": False}, 
)

start = time.time()
outputs = pipe(
    "data/VMP5922871816.mp3",
    chunk_length_s=30,
    batch_size=4,
    return_timestamps=True
)
end = time.time()

print(outputs)
print(end - start)
----

[options="header"]
|===
| Batch Size | Time 
|1 |08:54
| 2 | 06:50
|3 | 06:57
|4 | 06:40
|5 | 07:15
| 6 | 07:26
| 8 | 07:30
| 12 | 08:42
|===