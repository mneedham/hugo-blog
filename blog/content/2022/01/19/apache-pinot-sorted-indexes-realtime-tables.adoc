+++
draft = true
date="2022-01-19  00:44:37"
title="Apache Pinot: Sorted indexes on real-time tables"
tag=['pinot']
category=['Pinot']
description="In this post we'll learn all about sorted indexes on offline tables in Apache Pinot."
image="uploads/2022/01/indexes-banner.png"
+++

== Setup


=== Launch Components

*  Docker to launch all the components
*  Create the schema


.docker-compose.yml
[source, yaml]
----
version: '3.7'
services:
  zookeeper:
    image: zookeeper:3.5.6
    hostname: zookeeper
    container_name: zookeeper-strava-realtime
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
  kafka:
    image: wurstmeister/kafka:latest
    restart: unless-stopped
    container_name: "kafka-strava"
    ports:
      - "9092:9092"
    expose:
      - "9093"
    depends_on:
      - zookeeper
    environment:
      KAFKA_ZOOKEEPER_CONNECT: zookeeper-strava-realtime:2181/kafka
      KAFKA_BROKER_ID: 0
      KAFKA_ADVERTISED_HOST_NAME: kafka-strava
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-strava:9093,OUTSIDE://localhost:9092
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9093,OUTSIDE://0.0.0.0:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,OUTSIDE:PLAINTEXT
  pinot-controller:
    image: apachepinot/pinot:0.9.3
    command: "StartController -zkAddress zookeeper-strava-realtime:2181 -dataDir /data"
    container_name: "pinot-controller-strava-realtime"
    volumes:
      - ./config:/config
      - ./data-realtime:/data
    restart: unless-stopped
    ports:
      - "9000:9000"
    depends_on:
      - zookeeper
  pinot-broker:
    image: apachepinot/pinot:0.9.3
    command: "StartBroker -zkAddress zookeeper-strava-realtime:2181"
    restart: unless-stopped
    container_name: "pinot-broker-strava-realtime"
    ports:
      - "8099:8099"
    depends_on:
      - pinot-controller
  pinot-server:
    image: apachepinot/pinot:0.9.3
    command: "StartServer -zkAddress zookeeper-strava-realtime:2181"
    restart: unless-stopped
    container_name: "pinot-server-strava-realtime"
    depends_on:
      - pinot-broker
----

[source, bash]
----
docker-compose up
----

=== Create Schema

Let's also create a schema for our data:

./config/schema.json
[source, json]
----
include::content/2022/01/19/config/schema.json[]
----

[source, bash]
----
docker exec -it pinot-controller-strava-realtime bin/pinot-admin.sh AddSchema \
  -schemaFile /config/schema.json -exec
----

=== Create Tables


We're going to create both real-time and offline tables, but they will be completely independent - we're not creating a https://docs.pinot.apache.org/basics/components/table#hybrid-table-creation[hybrid table^].

[source, bash]
----
docker exec -it pinot-controller-strava-realtime bin/pinot-admin.sh AddTable   \
  -tableConfigFile /config/table-offline.json   \
  -exec
----

/home/markhneedham/projects/hugo-blog/blog/content/2022/01/19/config/table-offline.json

== What is a sorted index?

Before we ingest any data, let's remind ourselves about the definition of a sorted index.




[quote, Sorted forward index with run-length encoding, https://docs.pinot.apache.org/basics/indexing/forward-index#sorted-forward-index-with-run-length-encoding]
_____
When a column is physically sorted, Pinot uses a sorted forward index with run-length encoding on top of the dictionary-encoding. 
Instead of saving dictionary ids for each document id, Pinot will store a pair of start and end document ids for each value.
_____

.Sorted Forward Index
image::{{<siteurl>}}/uploads/2022/01/sorted-forward.png[]

== Sorted indexes on offline tables

Have some CSV files where the data is sorted by timestamp within each CSV file
In one of the files we can have the timestamps unsorted

Check the sorted status using the below:


[source, bash]
----
export queryString="columns=id&columns=altitude&columns=hr&columns=cadence&columns=rawTime&columns=distance&columns=lat&columns=lon&columns=location&columns=timestamp"
curl -X GET "http://localhost:9000/segments/activities/metadata?${queryString}" \
  -H "accept: application/json"  2>/dev/null | 
  jq -c '.[] | select(.columns != null) | [.segmentName, (.columns[] | [.columnName, .sorted])]'
----


== Sort indexes on real-time tables

Stream some values into Kafka with a very low threshold for flushing segments




Use a flush threshold of 5. 
In one of the groups of 5 we can have the timestamps in a mixed order. 
Then show how the sortedColumn works. 
